{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Project: Online Retail Exploratory Data Analysis with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, you will step into the shoes of an entry-level data analyst at an online retail company, helping interpret real-world data to help make a key business decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study\n",
    "In this project, you will be working with transactional data from an online retail store. The dataset contains information about customer purchases, including product details, quantities, prices, and timestamps. Your task is to explore and analyze this dataset to gain insights into the store's sales trends, customer behavior, and popular products. \n",
    "\n",
    "By conducting exploratory data analysis, you will identify patterns, outliers, and correlations in the data, allowing you to make data-driven decisions and recommendations to optimize the store's operations and improve customer satisfaction. Through visualizations and statistical analysis, you will uncover key trends, such as the busiest sales months, best-selling products, and the store's most valuable customers. Ultimately, this project aims to provide actionable insights that can drive strategic business decisions and enhance the store's overall performance in the competitive online retail market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Objectives\n",
    "1. Describe data to answer key questions to uncover insights\n",
    "2. Gain valuable insights that will help improve online retail performance\n",
    "3. Provide analytic insights and data-driven recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset you will be working with is the \"Online Retail\" dataset. It contains transactional data of an online retail store from 2010 to 2011. The dataset is available as a .xlsx file named `Online Retail.xlsx`. This data file is already included in the Coursera Jupyter Notebook environment, however if you are working off-platform it can also be downloaded [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx).\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "- InvoiceNo: Invoice number of the transaction\n",
    "- StockCode: Unique code of the product\n",
    "- Description: Description of the product\n",
    "- Quantity: Quantity of the product in the transaction\n",
    "- InvoiceDate: Date and time of the transaction\n",
    "- UnitPrice: Unit price of the product\n",
    "- CustomerID: Unique identifier of the customer\n",
    "- Country: Country where the transaction occurred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "You may explore this dataset in any way you would like - however if you'd like some help getting started, here are a few ideas:\n",
    "\n",
    "1. Load the dataset into a Pandas DataFrame and display the first few rows to get an overview of the data.\n",
    "2. Perform data cleaning by handling missing values, if any, and removing any redundant or unnecessary columns.\n",
    "3. Explore the basic statistics of the dataset, including measures of central tendency and dispersion.\n",
    "4. Perform data visualization to gain insights into the dataset. Generate appropriate plots, such as histograms, scatter plots, or bar plots, to visualize different aspects of the data.\n",
    "5. Analyze the sales trends over time. Identify the busiest months and days of the week in terms of sales.\n",
    "6. Explore the top-selling products and countries based on the quantity sold.\n",
    "7. Identify any outliers or anomalies in the dataset and discuss their potential impact on the analysis.\n",
    "8. Draw conclusions and summarize your findings from the exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Load Important Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import unidecode\n",
    "\n",
    "# Standard operational package imports.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization package imports.\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# Others\n",
    "import calendar as cal\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Important imports for preprocessing, modeling, and evaluation.\n",
    "from statsmodels.stats.outliers_influence \\\n",
    "    import variance_inflation_factor as smvif\n",
    "import statsmodels.formula.api as smfapi\n",
    "import statsmodels.api as smapi\n",
    "import statsmodels.tools.tools as smtools\n",
    "import statsmodels.stats.multicomp as smmulti\n",
    "import sklearn.model_selection as sklmodslct\n",
    "import sklearn.linear_model as skllinmod\n",
    "import sklearn.metrics as sklmtrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all my important data analysis functions\n",
    "import data_analysis_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "5    536365     22752         SET 7 BABUSHKA NESTING BOXES         2   \n",
      "6    536365     21730    GLASS STAR FROSTED T-LIGHT HOLDER         6   \n",
      "7    536366     22633               HAND WARMER UNION JACK         6   \n",
      "8    536366     22632            HAND WARMER RED POLKA DOT         6   \n",
      "9    536367     84879        ASSORTED COLOUR BIRD ORNAMENT        32   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
      "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "5 2010-12-01 08:26:00       7.65     17850.0  United Kingdom  \n",
      "6 2010-12-01 08:26:00       4.25     17850.0  United Kingdom  \n",
      "7 2010-12-01 08:28:00       1.85     17850.0  United Kingdom  \n",
      "8 2010-12-01 08:28:00       1.85     17850.0  United Kingdom  \n",
      "9 2010-12-01 08:34:00       1.69     13047.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "# load the online-retail dataset xlsx\n",
    "data = pd.read_excel(\"online-retail_dataset.xlsx\")\n",
    "data_analysis_functions.df_head(data,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Data Cleaning \n",
    "\n",
    "Perform data cleaning by handling missing values, if any, and removing any redundant or unnecessary columns.\n",
    "\n",
    "Also, to makesure datetime columns are actually in datetime and numeric columns are actually numeric and not strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number rows and columns before dropna(axis=0)\n",
      "rows = 541909\n",
      "columns = 8\n",
      "\n",
      "data types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    541909 non-null  object        \n",
      " 1   StockCode    541909 non-null  object        \n",
      " 2   Description  540455 non-null  object        \n",
      " 3   Quantity     541909 non-null  int64         \n",
      " 4   InvoiceDate  541909 non-null  datetime64[ns]\n",
      " 5   UnitPrice    541909 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  float64       \n",
      " 7   Country      541909 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 33.1+ MB\n",
      "None\n",
      "\n",
      "summary statistics:\n",
      "            Quantity                    InvoiceDate      UnitPrice  \\\n",
      "count  541909.000000                         541909  541909.000000   \n",
      "mean        9.552250  2011-07-04 13:34:57.156386048       4.611114   \n",
      "min    -80995.000000            2010-12-01 08:26:00  -11062.060000   \n",
      "25%         1.000000            2011-03-28 11:34:00       1.250000   \n",
      "50%         3.000000            2011-07-19 17:17:00       2.080000   \n",
      "75%        10.000000            2011-10-19 11:27:00       4.130000   \n",
      "max     80995.000000            2011-12-09 12:50:00   38970.000000   \n",
      "std       218.081158                            NaN      96.759853   \n",
      "\n",
      "          CustomerID  \n",
      "count  406829.000000  \n",
      "mean    15287.690570  \n",
      "min     12346.000000  \n",
      "25%     13953.000000  \n",
      "50%     15152.000000  \n",
      "75%     16791.000000  \n",
      "max     18287.000000  \n",
      "std      1713.600303  \n",
      "\n",
      "number rows and columns after dropna(axis=0)\n",
      "rows = 406829\n",
      "columns = 8\n",
      "24.93% missing (null) data\n",
      "                                InvoiceNo StockCode  \\\n",
      "0                                  536365    85123A   \n",
      "1                                  536365     71053   \n",
      "2                                  536365    84406B   \n",
      "3                                  536365    84029G   \n",
      "4                                  536365    84029E   \n",
      "...                                   ...       ...   \n",
      "388830         InvoiceNo\n",
      "128471    552575     22178   \n",
      "388831         InvoiceNo\n",
      "128472    552575     23144   \n",
      "388833           InvoiceNo\n",
      "6907    537195     21258   \n",
      "388834          InvoiceNo\n",
      "23988    539404     84978   \n",
      "388835         InvoiceNo\n",
      "325205    573911     20979   \n",
      "\n",
      "                                              Description  Quantity  \\\n",
      "0                      WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1                                     WHITE METAL LANTERN         6   \n",
      "2                          CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3                     KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4                          RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "...                                                   ...       ...   \n",
      "388830                              Description\n",
      "128471...       573   \n",
      "388831                              Description\n",
      "128472...       349   \n",
      "388833                       Description\n",
      "6907  VICTORI...        46   \n",
      "388834                              Description\n",
      "23988 ...       167   \n",
      "388835                            Description\n",
      "325205  ...         1   \n",
      "\n",
      "                                              InvoiceDate  UnitPrice  \\\n",
      "0                                     2010-12-01 08:26:00   2.550000   \n",
      "1                                     2010-12-01 08:26:00   3.390000   \n",
      "2                                     2010-12-01 08:26:00   2.750000   \n",
      "3                                     2010-12-01 08:26:00   3.390000   \n",
      "4                                     2010-12-01 08:26:00   3.390000   \n",
      "...                                                   ...        ...   \n",
      "388830                 InvoiceDate\n",
      "128471 2011-05-10 1...   1.677778   \n",
      "388831                 InvoiceDate\n",
      "128472 2011-05-10 1...   0.821538   \n",
      "388833               InvoiceDate\n",
      "6907 2010-12-05 13:55:00  11.113636   \n",
      "388834                InvoiceDate\n",
      "23988 2010-12-17 12:...   1.168571   \n",
      "388835                 InvoiceDate\n",
      "325205 2011-11-01 1...   1.250000   \n",
      "\n",
      "        CustomerID                                        Country  \n",
      "0          17850.0                                 United Kingdom  \n",
      "1          17850.0                                 United Kingdom  \n",
      "2          17850.0                                 United Kingdom  \n",
      "3          17850.0                                 United Kingdom  \n",
      "4          17850.0                                 United Kingdom  \n",
      "...            ...                                            ...  \n",
      "388830     14397.0                 Country\n",
      "128471  United Kingdom  \n",
      "388831     14397.0                 Country\n",
      "128472  United Kingdom  \n",
      "388833     15311.0                   Country\n",
      "6907  United Kingdom  \n",
      "388834     17315.0                  Country\n",
      "23988  United Kingdom  \n",
      "388835     17315.0                 Country\n",
      "325205  United Kingdom  \n",
      "\n",
      "[387758 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# get all data types of the columns\n",
    "print(\"number rows and columns before dropna(axis=0)\")\n",
    "data_analysis_functions.df_print_row_and_columns(data)\n",
    "old_row_numbers = data.shape[0]\n",
    "print(\"\")\n",
    "\n",
    "print(\"data types:\")\n",
    "data_analysis_functions.df_info_dtypes(data)\n",
    "print(\"\")\n",
    "#data_analysis_functions.df_info_dtypes(data)\n",
    "\n",
    "# get summary statistics\n",
    "print(\"summary statistics:\")\n",
    "print(data.describe())\n",
    "print(\"\")\n",
    "\n",
    "# removing empty rows\n",
    "data = data.dropna(axis=0).reset_index(drop=True)\n",
    "print(\"number rows and columns after dropna(axis=0)\")\n",
    "data_analysis_functions.df_print_row_and_columns(data)\n",
    "new_row_numbers = data.shape[0]\n",
    "\n",
    "# % missing data\n",
    "percentage_nadata = format(1-(new_row_numbers/old_row_numbers),\"0.2%\")\n",
    "print(\"{} missing (null) data\".format(percentage_nadata))\n",
    "\n",
    "# need to further mask using InvoiceNo\n",
    "returns = data[(data['Quantity'] < 0.0)]\n",
    "returns_customer_id = returns['CustomerID'].values.tolist()\n",
    "returns_unit_price = returns['StockCode'].values.tolist()\n",
    "mask_list = []\n",
    "data_returns_calculated = pd.DataFrame()\n",
    "for i in range(len(returns_customer_id)):\n",
    "    cust_id = returns_customer_id[i]\n",
    "    unit_p = returns_unit_price[i]\n",
    "    mask = (data['CustomerID'] == cust_id) & (data['StockCode'] == unit_p)\n",
    "    masked = data[mask]\n",
    "    mask_list += masked.index.tolist()\n",
    "    sum_quantity = masked['Quantity'].sum()\n",
    "    average_unit_p = masked['UnitPrice'].mean()\n",
    "    invoice_code = masked.iloc[0:1,0:1]\n",
    "    invoice_date = masked.iloc[0:1,4:5]\n",
    "    country = masked.iloc[0:1,7:8]\n",
    "    description = masked.iloc[0:1,2:3]\n",
    "    new_df_dict = {\"InvoiceNo\": [invoice_code], \"StockCode\": [unit_p], \"Description\": [description], \"Quantity\": [sum_quantity],\n",
    "              \"InvoiceDate\": [invoice_date], \"UnitPrice\": [average_unit_p], \"CustomerID\": [cust_id], \"Country\": [country]}\n",
    "    new_df = pd.DataFrame(new_df_dict)\n",
    "    data_returns_calculated = pd.concat([data_returns_calculated, new_df], ignore_index=True)\n",
    "mask_list = list(set(mask_list))   \n",
    "data_returns_filter = data.index.isin(mask_list)\n",
    "data_purchases_constructor = data[~data_returns_filter]\n",
    "data_purchases = pd.concat([data_purchases_constructor, data_returns_calculated], ignore_index=True)\n",
    "data_purchases = data_purchases[data_purchases['Quantity'] >= 0]\n",
    "print(data_purchases)\n",
    "\n",
    "# discount only\n",
    "discounts = data[data['Description'] == 'Discount']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT:\n",
    "All columns are of the expected data type. However there is negative quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number rows and columns after dropping negatives\n",
      "28.45% irrelevant (negative) data\n",
      "            Quantity      UnitPrice     CustomerID\n",
      "count  387758.000000  387758.000000  387758.000000\n",
      "mean       13.201938       3.035461   15294.693752\n",
      "std        62.216133      18.052927    1712.365073\n",
      "min         0.000000       0.000000   12346.000000\n",
      "25%         2.000000       1.250000   13969.000000\n",
      "50%         5.000000       1.850000   15159.000000\n",
      "75%        12.000000       3.750000   16795.000000\n",
      "max     12540.000000    8142.750000   18287.000000\n"
     ]
    }
   ],
   "source": [
    "# get all data only positive quantity and unitprice columns\n",
    "print(\"number rows and columns after dropping negatives\")\n",
    "neg_row_numbers = old_row_numbers - data_purchases.shape[0]\n",
    "percentage_negdata = format((neg_row_numbers/old_row_numbers),\"0.2%\")\n",
    "print(\"{} irrelevant (negative) data\".format(percentage_negdata))\n",
    "print(data_purchases.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Exploratory Data Analysis\n",
    "\n",
    "View the descriptive statistics such as mean, mode and median as well as standard deviation, range etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all exploratory stats about CENTRAL TENDENCY\n",
    "data_mode = data_purchases[['Quantity','UnitPrice','Country']].agg([pd.Series.mode])\n",
    "print(data_mode)\n",
    "data_mean = data_purchases[['Quantity','UnitPrice']].agg([pd.Series.mean])\n",
    "print(data_mean)\n",
    "data_median = data_purchases[['Quantity','UnitPrice']].agg([pd.Series.median])\n",
    "print(data_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all exploratory stats about SPREAD\n",
    "data_std = data_purchases[['Quantity','UnitPrice']].agg([pd.Series.std])\n",
    "print(data_std)\n",
    "data_skew = data_purchases[['Quantity','UnitPrice']].agg([pd.Series.skew])\n",
    "print(data_skew)\n",
    "print(\"\")\n",
    "# data_iqr = data[['Quantity','UnitPrice']].agg([pd.Series.quantile(q=0.25)])\\\n",
    "#           - data[['Quantity','UnitPrice']].agg([pd.Series.quantile(q=0.75)]) \n",
    "# print(data_iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite high skew in unit price which can be seen by th\n",
    "\n",
    "## Task 4: Data Visualisation \n",
    "\n",
    "To gain insights and to visualise outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use histogram\n",
    "fig = matplotlib.pyplot.subplots(figsize=(8, 6), dpi=85)\n",
    "sns.histplot(data=data_purchases, x=\"Quantity\")\n",
    "matplotlib.pyplot.xscale('log')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use boxplot to visualize extreme outliers\n",
    "fig2 = matplotlib.pyplot.subplots(figsize=(8, 6), dpi=85)\n",
    "data_purchases.boxplot(column=['Quantity'], return_type='axes')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use matrix scatter plot to visualise data relationships\n",
    "data_analysis_functions.df_pairplot(data_purchases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Analyse Trends over Time and also Analyse Busiest Months\n",
    "\n",
    "We will make another column called \"Total Price\", then divide the data into years by making a new \"Year\" column, and then strftime by month (New \"Month\" column) to visualise what the trends were like over the months\n",
    "1. Average Sale Quantity per month\n",
    "2. Average Price per Purchase\n",
    "3. Price per Invoice\n",
    "4. Total Sales per month\n",
    "5. Total Sales of particular product per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating total price column\n",
    "data_purchases.loc[:,\"TotalRevenue\"] = data_purchases[\"Quantity\"].multiply(data_purchases[\"UnitPrice\"])\n",
    "print(data_analysis_functions.df_head(data_purchases, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strfint year and month\n",
    "data_purchases.loc[:,\"YearMonth\"] = data_purchases.loc[:,\"InvoiceDate\"].dt.strftime(\"%Y-M%m\")\n",
    "print(data_analysis_functions.df_head(data_purchases, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly_revenue = data_analysis_functions.df_groupby_mask_operate(data_purchases, \"YearMonth\", \"TotalRevenue\", False, '0', 'mean')\n",
    "data_analysis_functions.df_grouped_barplotter(data_purchases, \"YearMonth\", \"TotalRevenue\", 1, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis_functions.df_grouped_barplotter(data_purchases, \"YearMonth\", \"TotalRevenue\", 1, 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean quantity purchased per purchase in countries\n",
    "data_analysis_functions.df_grouped_barplotter(data_purchases, \"Country\", \"Quantity\", 2, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total quantity purchased per countries\n",
    "data_analysis_functions.df_grouped_barplotter(data_purchases, \"Country\", \"TotalRevenue\", 2, 'sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UK had the most purchases by far, and also was the largest source of revenue even the the average sale price was lower.\n",
    "\n",
    "## TASK 6: Explore the top-selling products and countries based on the quantity sold.\n",
    "\n",
    "Here we shall simply groupby and aggreagate and show the products in terms of total revenue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total quantity purchased per product\n",
    "quantity_per_product = data_analysis_functions.df_groupby_mask_operate(data_purchases, \"Description\", \"Quantity\", False, \"0\", \"sum\")\n",
    "col = quantity_per_product.columns.tolist()\n",
    "quantity_per_product.sort_values(by=col, inplace=True, ascending=0)\n",
    "print(\"Ten higher selling products are:\")\n",
    "print(data_analysis_functions.df_head(quantity_per_product, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total revenue purchased per product\n",
    "revenue_per_product = data_analysis_functions.df_groupby_mask_operate(data_purchases, \"Description\", \"TotalRevenue\", False, \"0\", \"sum\")\n",
    "col = revenue_per_product.columns.tolist()\n",
    "revenue_per_product.sort_values(by=col, inplace=True, ascending=0)\n",
    "print(\"Ten higher grossing products are:\")\n",
    "print(data_analysis_functions.df_head(revenue_per_product, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Identify any outliers or anomalies in the dataset and discuss their potential impact on the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identification of outliers\n",
    "# method 1, percentile, we we set the outliers at the 90th percentile.\n",
    "percentile_ninenty = np.percentile(data_purchases['Quantity'], 90)\n",
    "data_outliers = data_purchases[data_purchases['Quantity'] > percentile_ninenty]\n",
    "print(data_outliers['Quantity'])\n",
    "data_purchases.loc[:,'Quantity'] = data_purchases.loc[:,'Quantity'].apply(lambda x: (percentile_ninenty if x > percentile_ninenty else x))\n",
    "print(data_purchases['Quantity'])\n",
    "\n",
    "# use boxplot to visualize extreme outliers\n",
    "#fig3 = matplotlib.pyplot.subplots(figsize=(8, 6), dpi=85)\n",
    "#data_purchases.boxplot(column=['Quantity'], return_type='axes')\n",
    "#matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see the outliers are removed,\n",
    "\n",
    "## Task 8: Draw conclusions and summarize your findings from the exploratory data analysis.\n",
    "\n",
    "1. We clearly see that the United Kingdom has the highest sales volume \n",
    "\n",
    "2. We can also see that there are outliers in quantities, but these are mitigated for and removed, the negative quantities and negative unit prices, we see that some of these are discounts and some of them were returns of a product. \n",
    "\n",
    "3. We also see that there is little correlation amongst any of the data fields here. \n",
    "\n",
    "4. We also see that the month with the highest sales volume was November 2011. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
