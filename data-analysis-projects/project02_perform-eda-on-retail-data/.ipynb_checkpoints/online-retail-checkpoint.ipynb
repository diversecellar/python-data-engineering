{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Project: Online Retail Exploratory Data Analysis with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, you will step into the shoes of an entry-level data analyst at an online retail company, helping interpret real-world data to help make a key business decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study\n",
    "In this project, you will be working with transactional data from an online retail store. The dataset contains information about customer purchases, including product details, quantities, prices, and timestamps. Your task is to explore and analyze this dataset to gain insights into the store's sales trends, customer behavior, and popular products. \n",
    "\n",
    "By conducting exploratory data analysis, you will identify patterns, outliers, and correlations in the data, allowing you to make data-driven decisions and recommendations to optimize the store's operations and improve customer satisfaction. Through visualizations and statistical analysis, you will uncover key trends, such as the busiest sales months, best-selling products, and the store's most valuable customers. Ultimately, this project aims to provide actionable insights that can drive strategic business decisions and enhance the store's overall performance in the competitive online retail market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Objectives\n",
    "1. Describe data to answer key questions to uncover insights\n",
    "2. Gain valuable insights that will help improve online retail performance\n",
    "3. Provide analytic insights and data-driven recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset you will be working with is the \"Online Retail\" dataset. It contains transactional data of an online retail store from 2010 to 2011. The dataset is available as a .xlsx file named `Online Retail.xlsx`. This data file is already included in the Coursera Jupyter Notebook environment, however if you are working off-platform it can also be downloaded [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx).\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "- InvoiceNo: Invoice number of the transaction\n",
    "- StockCode: Unique code of the product\n",
    "- Description: Description of the product\n",
    "- Quantity: Quantity of the product in the transaction\n",
    "- InvoiceDate: Date and time of the transaction\n",
    "- UnitPrice: Unit price of the product\n",
    "- CustomerID: Unique identifier of the customer\n",
    "- Country: Country where the transaction occurred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "You may explore this dataset in any way you would like - however if you'd like some help getting started, here are a few ideas:\n",
    "\n",
    "1. Load the dataset into a Pandas DataFrame and display the first few rows to get an overview of the data.\n",
    "2. Perform data cleaning by handling missing values, if any, and removing any redundant or unnecessary columns.\n",
    "3. Explore the basic statistics of the dataset, including measures of central tendency and dispersion.\n",
    "4. Perform data visualization to gain insights into the dataset. Generate appropriate plots, such as histograms, scatter plots, or bar plots, to visualize different aspects of the data.\n",
    "5. Analyze the sales trends over time. Identify the busiest months and days of the week in terms of sales.\n",
    "6. Explore the top-selling products and countries based on the quantity sold.\n",
    "7. Identify any outliers or anomalies in the dataset and discuss their potential impact on the analysis.\n",
    "8. Draw conclusions and summarize your findings from the exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Load Important Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import unidecode\n",
    "\n",
    "# Standard operational package imports.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization package imports.\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# Others\n",
    "import calendar as cal\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Important imports for preprocessing, modeling, and evaluation.\n",
    "from statsmodels.stats.outliers_influence \\\n",
    "    import variance_inflation_factor as smvif\n",
    "import statsmodels.formula.api as smfapi\n",
    "import statsmodels.api as smapi\n",
    "import statsmodels.tools.tools as smtools\n",
    "import statsmodels.stats.multicomp as smmulti\n",
    "import sklearn.model_selection as sklmodslct\n",
    "import sklearn.linear_model as skllinmod\n",
    "import sklearn.metrics as sklmtrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all my important data analysis functions\n",
    "import data_analysis_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "5    536365     22752         SET 7 BABUSHKA NESTING BOXES         2   \n",
      "6    536365     21730    GLASS STAR FROSTED T-LIGHT HOLDER         6   \n",
      "7    536366     22633               HAND WARMER UNION JACK         6   \n",
      "8    536366     22632            HAND WARMER RED POLKA DOT         6   \n",
      "9    536367     84879        ASSORTED COLOUR BIRD ORNAMENT        32   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
      "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "5 2010-12-01 08:26:00       7.65     17850.0  United Kingdom  \n",
      "6 2010-12-01 08:26:00       4.25     17850.0  United Kingdom  \n",
      "7 2010-12-01 08:28:00       1.85     17850.0  United Kingdom  \n",
      "8 2010-12-01 08:28:00       1.85     17850.0  United Kingdom  \n",
      "9 2010-12-01 08:34:00       1.69     13047.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "# load the online-retail dataset xlsx\n",
    "data = pd.read_excel(\"online-retail_dataset.xlsx\")\n",
    "data_analysis_functions.df_head(data,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Data Cleaning \n",
    "\n",
    "Perform data cleaning by handling missing values, if any, and removing any redundant or unnecessary columns.\n",
    "\n",
    "Also, to makesure datetime columns are actually in datetime and numeric columns are actually numeric and not strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number rows and columns before dropna(axis=0)\n",
      "rows = 541909\n",
      "columns = 8\n",
      "\n",
      "data types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    541909 non-null  object        \n",
      " 1   StockCode    541909 non-null  object        \n",
      " 2   Description  540455 non-null  object        \n",
      " 3   Quantity     541909 non-null  int64         \n",
      " 4   InvoiceDate  541909 non-null  datetime64[ns]\n",
      " 5   UnitPrice    541909 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  float64       \n",
      " 7   Country      541909 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 33.1+ MB\n",
      "None\n",
      "\n",
      "summary statistics:\n",
      "            Quantity                    InvoiceDate      UnitPrice  \\\n",
      "count  541909.000000                         541909  541909.000000   \n",
      "mean        9.552250  2011-07-04 13:34:57.156386048       4.611114   \n",
      "min    -80995.000000            2010-12-01 08:26:00  -11062.060000   \n",
      "25%         1.000000            2011-03-28 11:34:00       1.250000   \n",
      "50%         3.000000            2011-07-19 17:17:00       2.080000   \n",
      "75%        10.000000            2011-10-19 11:27:00       4.130000   \n",
      "max     80995.000000            2011-12-09 12:50:00   38970.000000   \n",
      "std       218.081158                            NaN      96.759853   \n",
      "\n",
      "          CustomerID  \n",
      "count  406829.000000  \n",
      "mean    15287.690570  \n",
      "min     12346.000000  \n",
      "25%     13953.000000  \n",
      "50%     15152.000000  \n",
      "75%     16791.000000  \n",
      "max     18287.000000  \n",
      "std      1713.600303  \n",
      "\n",
      "number rows and columns after dropna(axis=0)\n",
      "rows = 406829\n",
      "columns = 8\n",
      "24.93% missing (null) data\n"
     ]
    }
   ],
   "source": [
    "# get all data types of the columns\n",
    "print(\"number rows and columns before dropna(axis=0)\")\n",
    "data_analysis_functions.df_print_row_and_columns(data)\n",
    "old_row_numbers = data.shape[0]\n",
    "print(\"\")\n",
    "\n",
    "print(\"data types:\")\n",
    "data_analysis_functions.df_info_dtypes(data)\n",
    "print(\"\")\n",
    "\n",
    "# get summary statistics\n",
    "print(\"summary statistics:\")\n",
    "print(data.describe())\n",
    "print(\"\")\n",
    "\n",
    "# removing empty rows\n",
    "data = data.dropna(axis=0).reset_index(drop=True)\n",
    "print(\"number rows and columns after dropna(axis=0)\")\n",
    "data_analysis_functions.df_print_row_and_columns(data)\n",
    "new_row_numbers = data.shape[0]\n",
    "\n",
    "# % missing data\n",
    "percentage_nadata = format(1-(new_row_numbers/old_row_numbers),\"0.2%\")\n",
    "print(\"{} missing (null) data\".format(percentage_nadata))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns are of the expected data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Exploratory Data Analysis\n",
    "\n",
    "View the descriptive statistics such as mean, mode and median as well as standard deviation, range etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Quantity UnitPrice         Country\n",
      "      mode      mode            mode\n",
      "0        1      1.25  United Kingdom\n",
      "       Quantity  UnitPrice\n",
      "mean  12.061303   3.460471\n",
      "        Quantity  UnitPrice\n",
      "median       5.0       1.95\n"
     ]
    }
   ],
   "source": [
    "# get all exploratory stats about CENTRAL TENDENCY\n",
    "data_mode = data[['Quantity','UnitPrice','Country']].agg([pd.Series.mode])\n",
    "print(data_mode)\n",
    "data_mean = data[['Quantity','UnitPrice']].agg([pd.Series.mean])\n",
    "print(data_mean)\n",
    "data_median = data[['Quantity','UnitPrice']].agg([pd.Series.median])\n",
    "print(data_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Quantity  UnitPrice\n",
      "std  248.69337  69.315162\n",
      "      Quantity   UnitPrice\n",
      "skew  0.182663  452.219019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all exploratory stats about SPREAD\n",
    "data_std = data[['Quantity','UnitPrice']].agg([pd.Series.std])\n",
    "print(data_std)\n",
    "data_skew = data[['Quantity','UnitPrice']].agg([pd.Series.skew])\n",
    "print(data_skew)\n",
    "print(\"\")\n",
    "# data_iqr = data[['Quantity','UnitPrice']].agg([pd.Series.quantile(q=0.25)])\\\n",
    "#           - data[['Quantity','UnitPrice']].agg([pd.Series.quantile(q=0.75)]) \n",
    "# print(data_iqr)\n",
    "\n",
    "# use histogram with vertical axlines for mean and mode and the like-\n",
    "data_analysis_functions.df_histplotter(data, \"Quantity\", 2)\n",
    "data_analysis_functions.df_histplotter(data, \"UnitPrice\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite high skew in unit price which can be seen by th\n",
    "\n",
    "## Task 2: Data Cleaning \n",
    "\n",
    "Perform data cleaning by handling missing values, if any, and removing any redundant or unnecessary columns.\n",
    "\n",
    "Also, to makesure datetime columns are actually in datetime and numeric columns are actually numeric and not strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
