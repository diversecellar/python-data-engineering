





# your code here
import unidecode

# Standard operational package imports.
import pandas as pd
import numpy as np

# Visualization package imports.
import matplotlib
import seaborn as sns

# Others
import calendar as cal
import re
import random

# Important imports for preprocessing, modeling, and evaluation.
from statsmodels.stats.outliers_influence \
    import variance_inflation_factor as smvif
import statsmodels.formula.api as smfapi
import statsmodels.api as smapi
import statsmodels.tools.tools as smtools
import statsmodels.stats.multicomp as smmulti
import sklearn.model_selection as sklmodslct
import sklearn.linear_model as skllinmod
import sklearn.metrics as sklmtrcs


# importing all my important data analysis functions
import data_analysis_functions





# generating random dates in the year 2024
# intitialise dataframe
data_twitter = pd.DataFrame()
intended_sample_size = 650

# initialising random dates
start_date = pd.to_datetime('2024-01-01')
end_date = pd.to_datetime('2024-12-31')
days_in_year = (end_date-start_date).days # this correspnds to number of total tweets
data_twitter['Date'] = start_date + pd.to_timedelta\
    (np.random.randint(days_in_year,size=intended_sample_size), unit='d')
data_analysis_functions.df_head(data_twitter,10)


# categories
categories = ["Fashion", "Fitness", "Music", "Culture",\
              "Politics", "Family", "Health"]
data_twitter['Category'] = [random.choice(categories) for _ in range(intended_sample_size)]
data_analysis_functions.df_head(data_twitter,10)


# categories
realistic_likes_threshold = 2500
num_likes = np.random.randint(realistic_likes_threshold,size=intended_sample_size)
data_twitter['Num_of_Likes'] = [random.choice(num_likes) for _ in range(intended_sample_size)]
data_analysis_functions.df_head(data_twitter,10)


# descriptive stats about our df
# print data types
data_analysis_functions.df_info_dtypes(data_twitter)
# descriptive summary
print(data_twitter.describe())
# counts of each category element
category_counts = data_analysis_functions.df_groupby_mask_operate(data_twitter,\
    'Category', 'Category', 0, '0', 'count')
print(category_counts)
    


# removing all possible null data
data_twitter = data_twitter.dropna(axis=0).reset_index(drop=True)

# convert dataframe date fields to datetime (already done)
data_analysis_functions.df_datetime_converter(data_twitter)
data_analysis_functions.df_head(data_twitter,10)


# plot histogram of likes
data_analysis_functions.df_histplotter(data_twitter, "Num_of_Likes",2)


# boxplot of category
data_analysis_functions.df_boxplotter(data_twitter, "Category", "Num_of_Likes",2)


# mean likes 
mean_likes = np.round(data_twitter['Num_of_Likes'].agg(['mean']).values[0],2)
print("There are an average of {} Likes per tweet".format(mean_likes))


# mean likes grouped by category
mean_likes_grouped = data_analysis_functions.df_groupby_mask_operate(data_twitter,\
                        'Category', 'Num_of_Likes', 0, '0', 'mean')
print(mean_likes_grouped)








# one way Linear Regression Analysis
data_analysis_functions.lr_ols_model(data_twitter, col_response="Num_of_Likes",\
                col_cont_predictors=[], col_cat_predictors=["Category"])






